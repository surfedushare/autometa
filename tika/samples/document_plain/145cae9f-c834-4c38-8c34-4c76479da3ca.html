<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta name="cp:revision" content="6" />
<meta name="extended-properties:AppVersion" content="14.0000" />
<meta name="http-connection:target-ip-address" content="20.56.8.62" />
<meta name="meta:paragraph-count" content="47" />
<meta name="meta:word-count" content="3544" />
<meta name="dc:creator" content="Lavinia Marin" />
<meta name="extended-properties:Company" content="TU Delft" />
<meta name="dcterms:created" content="2022-02-23T10:22:00Z" />
<meta name="meta:line-count" content="168" />
<meta name="dcterms:modified" content="2022-02-23T13:39:00Z" />
<meta name="http-connection:target-url" content="https://api.acc.surfsharekit.nl/api/v1/files/repoItemFiles/145cae9f-c834-4c38-8c34-4c76479da3ca" />
<meta name="meta:character-count" content="20201" />
<meta name="meta:character-count-with-spaces" content="23698" />
<meta name="extended-properties:TotalTime" content="22" />
<meta name="Content-Length" content="0" />
<meta name="http-header:content-type" content="application/vnd.openxmlformats-officedocument.wordprocessingml.document" />
<meta name="Content-Type" content="application/vnd.openxmlformats-officedocument.wordprocessingml.document" />
<meta name="custom:ContentTypeId" content="0x0101003379F1BC3348A944AE486A5C2DF33F0C" />
<meta name="http-header:status-code" content="200" />
<meta name="extended-properties:Application" content="Microsoft Macintosh Word" />
<meta name="meta:last-author" content="Tijn Borghuis" />
<meta name="xmpTPg:NPages" content="9" />
<meta name="resourceName" content="/api/v1/files/repoItemFiles/145cae9f-c834-4c38-8c34-4c76479da3ca" />
<meta name="http-connection:num-redirects" content="1" />
<meta name="extended-properties:Template" content="Normal.dotm" />
<meta name="X-TIKA:Parsed-By" content="org.apache.tika.parser.DefaultParser" />
<meta name="X-TIKA:Parsed-By" content="org.apache.tika.parser.microsoft.ooxml.OOXMLParser" />
<meta name="extended-properties:DocSecurityString" content="None" />
<meta name="meta:page-count" content="9" />
<meta name="dc:publisher" content="TU Delft" />
<title></title>
</head>
<body><p>Fake News </p>
<p>Teacher version </p>
<p />
<p><b>Exercise title</b>: Fake News</p>
<p><b>Authors and affiliation</b>: </p>
<p>Julia Hermann, UT <a href="https://orcid.org/0000-0002-3232-1656">https://orcid.org/0000-0002-3232-1656</a></p>
<p>Merel Noorman, Tilburg University <a href="https://orcid.org/0000-0002-1658-3760">https://orcid.org/0000-0002-1658-3760</a></p>
<p><b>Case editor(s) and affiliation:</b> </p>
<p>Joep Jan Meerdink, TU/e</p>
<p><b>Persistent identifier of the Case-based Exercise</b></p>
<p>DOI: </p>
<p />
<p><b>Short abstract</b>: Social media companies face increasing pressure to address the spread of fake news, with it majorly affecting public opinion in recent years. In this CBE, students will develop a position on what changes companies should make in their approach to dealing with fake news. The CBE offers use of extended literature and the ethical cycle procedure to make students develop arguments to support their position. The reasoned position will be orally presented, with other students arguing against it. Finally, the reasoned position (with rebuttal of objections) will be written down in a report.</p>
<p />
<p><b>Story</b>: In the past few years, fake news has increasingly become an ever more pressing problem for social media platforms. Individuals, groups and even states with nefarious intentions have tried to affect public opinion through posting misleading news articles, doctored photos and videos as well as unsupported claims, thereby steering debates, influencing elections or discrediting particular individuals or groups. Most recently, such fake news campaigns were observed in the aftermath of the Christ Church shooting in New Zealand and the Notre Dame fire. Fake news items by themselves are harmless, but when they go viral across the internet as a result of unsuspecting social media users or the less-innocent armies of trolls massively sharing them, they can become harmful, for instance when they contribute to the further polarization of groups or damage the reputation of particular individuals. Social media companies, including Twitter, Google, and Facebook, as well as news organizations face increasing pressure to address the spread of fake news. </p>
<p>Social media companies and news organizations have taken steps to deal with fake news, including employing fact checkers and automating the detection of fake news items. Such measures often involve value tradeoffs, diverse stakeholders, and conflicting interests. To design and make decisions about appropriate measures, companies must consider values like freedom of speech, freedom of association, equality, public safety and security, as well as other factors, like company goals, legal obligations, obligations to shareholders, reputation, and financial interests. In the past few years, company policies on these questions have attracted attention from politicians, the public, etc., and the companies are increasingly asked to defend whatever fake news policies they decide to implement. </p>
<p class="normal1">In this assignment, students will develop and defend a position on an ethical problem related to fake news. To do this, they will use concepts and theories from social sciences and ethics.</p>
<p />
<p><b>Educational instructions</b></p>
<p>This exercises uses the Ethical Cycle format, of which an extended description is available in the 4TU.Ethics collection.</p>
<p><u>Step 1: Getting to know the topics and the problem of Fake News</u></p>
<p><b>Input</b>: Story, articles in “General Resources” and “Topic-Specific Resources”, the handout (student version of this cbe).</p>
<p><b>Activity</b>: Students form their groups autonomously and decide together on what topic to work on (Google, Instagram, Reddit, Twitter, a news aggregator of their choice). Groups then familiarize themselves with the general problem of Fake News by reading their own selection of sources provided in “General Resources”. They are also asked to read articles specifically related to their topic of choice, which are provided in “Topic-Specific Resources”, and to look for any additional relevant literature. The reading of these sources may be divided amongst group members. Students discuss their insights within their groups to create a well-rounded understanding of the problem amongst all members.</p>
<p><b>Output</b>: Written piece on findings of literature research.</p>
<p />
<p><u>Step 2: Defining a position</u></p>
<p><b>Input</b>: Findings of literature research (output step 1), assignment question (this step presupposes that students are familiar with the ethical cycle and ethical frameworks used therein, if not lectures or other additional activities to create this condition are required).  </p>
<p><b>Activity</b>: Student groups apply the ethical cycle in order to reach a position on their ethical question, starting from the assignment question: <i>What is one change that this company should make in its approach to dealing with fake news?</i> (where the company follows from the chosen topic). While applying the ethical cycle, students are asked to find relevant additional resources if needed. </p>
<p><u>Phase 1 Moral Problem Statement</u> students narrow down an ethical problem with fake news, by answering the questions: what is the problem with the situation, who has to act (the company), and what is the moral nature of the problem? (which norms/values are conflicting here?)  </p>
<p><u>Phase 2 Problem Analysis</u> students analyse the situation, by identifying stakeholders and their interests, relevant moral values and relevant, uncertain and possibly missing facts. </p>
<p><u>Phase 3 Options for Action</u> students come up with various feasible options for action for the agent (company) that has to act. </p>
<p><u>Phase 4 Ethical Evaluation</u> students evaluate the different options in a number of ethical frameworks. The informal intuition and common sense frameworks can provide a good start, formal frameworks Utilitarianism, Deontology and Virtue Ethics can be used, and for this CBE in particular, frameworks such as Value Ethics or Mediation Theory could be useful. </p>
<p><u>Phase 5 Reflection</u> students reflect on the outcomes of the evaluations in the different frameworks to come to a well-argued stance on the best option for action. Useful questions for this step include: “Does an ethical framework succeed in selecting those features of a situation that are morally relevant?” and “Does an ethical framework provide reasons that support my intuitive opinion?”. Criticizing the frameworks (as in moral philosophy) might also help to come to a well-rounded conclusion. </p>
<p><b>Output</b>: A written and well-argued position on the ethical question, structured by the steps of the ethical cycle.</p>
<p />
<p><u>Step 3: Presenting the position</u></p>
<p><b>Input</b>: The group’s research and position on the ethical question (output step 2).</p>
<p><b>Activity</b>: Student groups prepare a 10 minute presentation that explains their position and an argument for that position. The argument should be grounded in the literature research, the ethical cycle analysis, and also an analysis of relevance and feasibility of their recommended option for action. They are also asked to prepare responses to objections to their position. </p>
<p>These presentations will take place in a larger session. While one group is presenting, other groups will be asked to be the audience,  actively raise objections to the groups that present positions to the same topic they’ve been working on. Next to objections, the listening groups should also pose generally helpful or insightful questions. After each presentation, the instructor will randomly select at least one listening group to share their questions and objections. The presenting group will then have time to respond and defend. The presenting group should take note of the most important objections raised.</p>
<p><b>Output</b>: A 10 min. presentation, debate and discussion among groups.</p>
<p />
<p><u>Step 4: Written report</u></p>
<p><b>Input</b>: All previously gained insights on a group’s specific topic (output steps 1-3)</p>
<p><b>Activity</b>: The groups will spend time preparing a written report, including at least their position on the ethical question, their argument for that position (supported by their literature research and ethical cycle analysis), the most important objection to their position, and their response to that objection. The objection can stem from the feedback they got after presenting, but may also be an objection they came up with themselves.</p>
<p><a name="_GoBack" /><b>Output</b>: A written report (2000-2500 words).</p>
<p />
<p><b>Rubric sketch for the CBE:</b></p>
<p />
<table><tbody><tr>	<td><p>Step</p>
</td>	<td><p>Unsatisfactory</p>
</td>	<td><p>OK/Satisfactory</p>
</td>	<td><p>Excellent</p>
</td></tr>
<tr>	<td><p>1</p>
</td>	<td><p>Read and discussed too little of general resources / Minimal understanding of problem and/or topic</p>
</td>	<td><p>Read a selection of general resources / decent understanding of problem and topic / literature selection paints somewhat one-sided picture / no additional literature</p>
</td>	<td><p>Read a good selection of general resources and additional literature / good and well-rounded understanding of problem and topic</p>
</td></tr>
<tr>	<td><p>2</p>
</td>	<td><p>Did not (properly) apply ethical cycle / developed no defined position on the ethical question</p>
</td>	<td><p>Developed a defined position on the ethical question / A connection to literature research and ethical cycle is present</p>
</td>	<td><p>Developed a defined position on the ethical question / Strong and clear connection to (additional) literature research and ethical cycle is present.</p>
</td></tr>
<tr>	<td><p>3.</p>
<p />
</td>	<td><p><b>Presenting</b></p>
<p>No presentation / incoherent story / weak argumentation or link to process /</p>
</td>	<td><p><b>Presenting</b></p>
<p>Coherent position based on process / slight relevancy and/or feasibility issues / weak defence against objection</p>
</td>	<td><p><b>Presenting</b></p>
<p>Coherent position based on process / relevant and feasible recommendation / decent to strong defence against objection</p>
</td></tr>
<tr>	<td><p>3.</p>
</td>	<td><p><b>Listening</b></p>
<p>Not present / no input on questions and/or objections</p>
</td>	<td><p><b>Listening</b></p>
<p>Some effort put into questions and objections / quality or quantity of feedback could be better / presenting groups gain little insight from feedback</p>
</td>	<td><p><b>Listening</b></p>
<p>Considerable effort put into questions and objections / quality and quantity of feedback is good / presenting groups gain strong insight and receive valuable objections</p>
</td></tr>
<tr>	<td><p>4.</p>
</td>	<td><p>No report / missing requirements / no clear definition or argumentation of position / no attempt to defend against objections</p>
</td>	<td><p>All requirements present / coherent position based on research / weak defence against objections</p>
</td>	<td><p>All requirements present / coherent based on extensive research / decent to strong defence against objection</p>
</td></tr>
</tbody></table>
<p />
<p />
<p><b>References</b>: </p>
<p><b><i>General Resources (for all topics):</i></b></p>
<p class="list_Paragraph">1. <b>Fake News – background:</b></p>
<p class="list_Paragraph">1. Tandoc Jr., E.C., Lim, Z.W. and Ling, R. (2018), “Defining ‘Fake News’”, Digital Journalism 6/2, 137-153. <a href="https://www.tandfonline.com/doi/full/10.1080/21670811.2017.1360143">https://www.tandfonline.com/doi/full/10.1080/21670811.2017.1360143</a></p>
<p class="list_Paragraph">1. Egelhofer. J.L. and Lecheler, S. (2019), “Fake News as a Two-Dimensional Phenomenon: A Framework and Research Agenda”, <i>Annals of the International Communications Association</i>. <a href="https://doi.org/10.1080/23808985.2019.1602782">https://doi.org/10.1080/23808985.2019.1602782</a></p>
<p class="list_Paragraph">1. Ball, P. (8 March, 2018). “’News’ spreads faster and more widely when it’s false". <i>Nature</i>. <a href="https://www.nature.com/articles/d41586-018-02934-x">https://www.nature.com/articles/d41586-018-02934-x</a></p>
<p class="list_Paragraph">1. Roberts, Sarah T. March, 2017. Social Media’s Silent Filter. <i>The Atlantic</i>. <a href="https://www.theatlantic.com/technology/archive/2017/03/commercial-content-moderation/518796/">https://www.theatlantic.com/technology/archive/2017/03/commercial-content-moderation/518796/</a></p>
<p class="list_Paragraph">1. Filloux F, 2018. “Fighting fake news is a losing battle, but there are other ways to win the war. ”<a href="https://mondaynote.com/fighting-fake-news-is-a-losing-battle-but-there-are-other-ways-to-win-the-war-1991ed877478">https://mondaynote.com/fighting-fake-news-is-a-losing-battle-but-there-are-other-ways-to-win-the-war-1991ed877478</a></p>
<p class="list_Paragraph" />
<p class="list_Paragraph">1. <b>Risks associated with fake news:</b></p>
<p class="list_Paragraph">0. Bakir, V. and McStay, A. (2018). “Fake News and the Economy of Emotions”. Digital Journalism 6/2, 154-175. <a href="https://doi.org/10.1080/21670811.2017.1345645">https://doi.org/10.1080/21670811.2017.1345645</a></p>
<p class="list_Paragraph">0. Carlson, M. (2018). “Fake news as an informational moral panic: the symbolic</p>
<p class="list_Paragraph">deviancy of social media during the 2016 US presidential election”, <i>Information, Communication &amp; Society</i>. <a href="https://doi.org/10.1080/1369118X.2018.1505934">https://doi.org/10.1080/1369118X.2018.1505934</a></p>
<p class="list_Paragraph">0. Lytvynenko &amp; Silverman (2019). A Timeline of How The Notre Dame Fire Was Turned Into An Anti-Muslim Narrative. Buzzfeed. <a href="https://www.buzzfeednews.com/article/janelytvynenko/notre-dame-hoax-timeline">https://www.buzzfeednews.com/article/janelytvynenko/notre-dame-hoax-timeline</a></p>
<p class="list_Paragraph">0. Taub, Amanda and Max Fisher. April 24, 2018. “Where Countries Are Tinderboxes and Facebook Is a Match.” <i>The New York Times</i>.  <a href="https://www.nytimes.com/2018/04/21/world/asia/facebook-sri-lanka-riots.html">https://www.nytimes.com/2018/04/21/world/asia/facebook-sri-lanka-riots.html</a></p>
<p class="list_Paragraph">0. Wittenberg M, 2018. “Fake news, rumour and censorship in the Middle Kingdom”. <i>Medium</i>. <a href="https://mondaynote.com/fake-news-rumour-and-censorship-in-the-middle-kingdom-89d48f08b5d4">https://mondaynote.com/fake-news-rumour-and-censorship-in-the-middle-kingdom-89d48f08b5d4</a></p>
<p class="list_Paragraph">0. Greene L, 2019. “The Future Of Fake News And Its Consequences To Society”. <a href="https://www.huffingtonpost.in/entry/silicon-states-excerpt-fake-news-future_in_5cc1fe2de4b031dc07ef97b5">https://www.huffingtonpost.in/entry/silicon-states-excerpt-fake-news-future_in_5cc1fe2de4b031dc07ef97b5</a></p>
<p class="list_Paragraph" />
<p class="list_Paragraph">1. <b>Policy measures/laws for dealing with fake news: </b></p>
<p class="list_Paragraph">2. Policy Department for Economic, Scientific and Quality of Life Policies, Andrea Renda (CEPS - Centre for European Policy Studies and College of Europe), Directorate-General for Internal Policies. PE 619.013- June 2018. <a href="https://www.europarl.europa.eu/RegData/etudes/IDAN/2018/619013/IPOL_IDA(2018)619013_EN.pdf">https://www.europarl.europa.eu/RegData/etudes/IDAN/2018/619013/IPOL_IDA(2018)619013_EN.pdf</a></p>
<p class="list_Paragraph">2. Singapore Fake News Bill 2019. <a href="https://www.parliament.gov.sg/docs/default-source/default-document-library/protection-from-online-falsehoods-and-manipulation-bill10-2019.pdf">https://www.parliament.gov.sg/docs/default-source/default-document-library/protection-from-online-falsehoods-and-manipulation-bill10-2019.pdf</a></p>
<p class="list_Paragraph">2. Vaswani K, 2019. “Convern over Singapore’s anti-fake news law”. <a href="https://www.bbc.com/news/business-47782470">https://www.bbc.com/news/business-47782470</a></p>
<p class="list_Paragraph">2. <a href="https://www.ikigailaw.com/the_fake_news_problem/">https://www.ikigailaw.com/the_fake_news_problem/#acceptLicense</a></p>
<p class="list_Paragraph">2. https://www.poynter.org/ifcn/anti-misinformation-actions/</p>
<p />
<p class="list_Paragraph">1. <b>Other methods of dealing with fake news:</b></p>
<p class="list_Paragraph">1. Jarvais J 2016, “A Call for Cooperation Against Fake News” (Medium). <a href="https://medium.com/whither-news/a-call-for-cooperation-against-fake-news-d7d94bb6e0d4">https://medium.com/whither-news/a-call-for-cooperation-against-fake-news-d7d94bb6e0d4</a></p>
<p class="list_Paragraph">1. <a href="https://www.ebu.ch/files/live/sites/ebu/files/Publications/Position%20papers/EBU-Position-EN-Fake_News_Disinformation-18.04.2018.pdf">https://www.ebu.ch/files/live/sites/ebu/files/Publications/Position%20papers/EBU-Position-EN-Fake_News_Disinformation-18.04.2018.pdf</a></p>
<p class="list_Paragraph">1. Tiku N, 2016. “Why Snapchat And Apple Don't Have A Fake News Problem” <a href="https://www.buzzfeednews.com/article/nitashatiku/snapchat-fake-news">https://www.buzzfeednews.com/article/nitashatiku/snapchat-fake-news</a></p>
<p />
<p class="list_Paragraph">1. <b>Automating fake news detection:</b></p>
<p class="list_Paragraph">1. Feamster, Nick. March 21, 2018. “Artificial Intelligence and the Future of Online Content Moderation.” (Blogpost). <i>Freedom to Tinker</i> <a href="https://freedom-to-tinker.com/2018/03/21/artificial-intelligence-and-the-future-of-online-content-moderation/">https://freedom-to-tinker.com/2018/03/21/artificial-intelligence-and-the-future-of-online-content-moderation/</a></p>
<p class="list_Paragraph">1. Duarte, N., Llanso, E., &amp; Loup, A. Jan, 2018. Mixed Messages? The Limits of Automated Social Media Content Analysis. In <i>Conference on Fairness, Accountability and Transparency</i> (pp. 106-106). <a href="https://cdt.org/files/2017/12/FAT-conference-draft-2018.pdf">https://cdt.org/files/2017/12/FAT-conference-draft-2018.pdf</a> </p>
<p class="list_Paragraph">1. <a href="http://www.fakenewschallenge.org">http://www.fakenewschallenge.org</a></p>
<p class="list_Paragraph">1. Edell A, 2018. ‘I trained fake news detection AI with &gt;95% accuracy, and almost went crazy’. (Medium). <a href="https://towardsdatascience.com/i-trained-fake-news-detection-ai-with-95-accuracy-and-almost-went-crazy-d10589aa57c">https://towardsdatascience.com/i-trained-fake-news-detection-ai-with-95-accuracy-and-almost-went-crazy-d10589aa57c</a></p>
<p class="list_Paragraph">1. <a href="https://www.firstpost.com/tech/news-analysis/algorithm-based-automated-solution-can-indentify-fake-news-better-than-humans-research-5018041.html">https://www.firstpost.com/tech/news-analysis/algorithm-based-automated-solution-can-indentify-fake-news-better-than-humans-research-5018041.html</a></p>
<p class="list_Paragraph">1. <a href="https://towardsdatascience.com/fake-news-or-not-edad1552aa02">https://towardsdatascience.com/fake-news-or-not-edad1552aa02</a></p>
<p />
<p><b><i>Topic-specific resources:</i></b></p>
<p><b>Instagram</b></p>
<p class="list_Paragraph">1. Tahir T, 2018. “FAKE VIEWS. Instagram was a BIGGER fake news tool than Facebook during Kremlin’s 2016 US election misinformation campaign, bombshell report says” <i>The Sun UK. </i><a href="https://www.thesun.co.uk/news/8001784/instagram-bigger-fake-news-facebook-us-election-misinformation/">https://www.thesun.co.uk/news/8001784/instagram-bigger-fake-news-facebook-us-election-misinformation/</a></p>
<p class="list_Paragraph">1. Chaturvedi A, 2019. “Fake news makes it to Instagram now”. <a href="https://economictimes.indiatimes.com/tech/internet/fake-news-makes-it-to-instagram-now/articleshow/68915164.cms">https://economictimes.indiatimes.com/tech/internet/fake-news-makes-it-to-instagram-now/articleshow/68915164.cms</a></p>
<p class="list_Paragraph">1. Alexrod T, 2018. “Instagram rolls out new measures to combat ‘fake news’”. <a href="https://thehill.com/policy/cybersecurity/404003-instagram-rolls-out-new-measures-to-combat-fake-news">https://thehill.com/policy/cybersecurity/404003-instagram-rolls-out-new-measures-to-combat-fake-news</a></p>
<p class="list_Paragraph">1. Frank S, 2019. “Conspiracy theories and extremism reportedly thrive on Instagram”. <a href="https://www.cbsnews.com/news/instagram-conspiracy-theories-extremism-hate-thrive-atlantic-monthly-report/">https://www.cbsnews.com/news/instagram-conspiracy-theories-extremism-hate-thrive-atlantic-monthly-report/</a></p>
<p />
<p><b>Twitter</b></p>
<p class="list_Paragraph">1. From Twitter:</p>
<p class="list_Paragraph">0. “The Twitter rules”: <a href="https://help.twitter.com/en/rules-and-policies/twitter-rules">https://help.twitter.com/en/rules-and-policies/twitter-rules</a></p>
<p class="list_Paragraph">1. Wolverton, Troy. April 11, 2018. “Twitter investors take aim at fake news, hate speech, and harassment — but the company says it's already doing all it can.” <i>Business Insider.</i> <a href="http://www.businessinsider.com/a-twitter-shareholder-proposal-requests-a-report-on-fake-news-and-more-2018-4?international=true&amp;r=US&amp;IR=T">http://www.businessinsider.com/a-twitter-shareholder-proposal-requests-a-report-on-fake-news-and-more-2018-4?international=true&amp;r=US&amp;IR=T</a>) </p>
<p class="list_Paragraph">1. See also “Proposal No. 5 Stockholder proposal regarding a report on our content enforcement policies” (Pages 39-41 only.) <a href="https://www.sec.gov/Archives/edgar/data/1418091/000119312518114213/d491570ddef14a.htm">https://www.sec.gov/Archives/edgar/data/1418091/000119312518114213/d491570ddef14a.htm</a> </p>
<p class="list_Paragraph">1. Binder M, 2019. “Twitter adds option to report attempts to mislead voters” <a href="https://mashable.com/article/twitter-reporting-feature-misleading-voting-elections/?europe=true">https://mashable.com/article/twitter-reporting-feature-misleading-voting-elections/?europe=true</a></p>
<p class="list_Paragraph">1. Binder M, 2018. “Study: Twitter isn’t doing enough to combat ‘fake news’”. <a href="https://mashable.com/article/study-twitter-fake-news/?europe=true">https://mashable.com/article/study-twitter-fake-news/?europe=true</a></p>
<p />
<p><b>Google</b></p>
<p class="list_Paragraph">1. Binder M, 2019, “Google cracked down on 2.3 billion bad ads last year”. <a href="https://mashable.com/article/google-bad-ads-report/?europe=true">https://mashable.com/article/google-bad-ads-report/?europe=true</a></p>
<p class="list_Paragraph">1. England R, 2019. “Google explains how it's fighting fake news”. <a href="https://www.engadget.com/2019/02/19/google-explains-how-it-is-fighting-fake-news/">https://www.engadget.com/2019/02/19/google-explains-how-it-is-fighting-fake-news/</a></p>
<p class="list_Paragraph">1. Abril D, 2019. “Google Introduces New Tools to Help Journalists Fight Fake News”. <a href="http://fortune.com/2019/03/20/google-new-tools-fight-fake-news/">http://fortune.com/2019/03/20/google-new-tools-fight-fake-news/</a></p>
<p class="list_Paragraph">1. Stewart T, 2019. “Google prepares for EU elections fake news battle”. <a href="https://www.mobilemarketingmagazine.com/google-youtube-european-parliament-elections-fake-news-misinformation">https://www.mobilemarketingmagazine.com/google-youtube-european-parliament-elections-fake-news-misinformation</a></p>
<p />
<p><b>Reddit </b></p>
<p class="list_Paragraph">1. Couric K, Podcast-54 mins, 2018. “Reddit's CEO on Fake News and Free Speech” <a href="https://www.stitcher.com/podcast/stitcher/katie-couric/e/55392132">https://www.stitcher.com/podcast/stitcher/katie-couric/e/55392132</a></p>
<p class="list_Paragraph">1. Marantz A, 2018. “Reddit and the Struggle to Detoxify the Internet”. <i>The New Yorker. </i><a href="https://www.newyorker.com/magazine/2018/03/19/reddit-and-the-struggle-to-detoxify-the-internet">https://www.newyorker.com/magazine/2018/03/19/reddit-and-the-struggle-to-detoxify-the-internet</a></p>
<p class="list_Paragraph">1. Koetsier J, 2018. “Reddit CTO On Fake News, QAnon, Harassment, And Running 'The Front Page Of The Internet'”. <a href="https://www.forbes.com/sites/johnkoetsier/2018/08/09/reddit-cto-on-fake-news-qanon-harassment-and-running-the-front-page-of-the-internet/">https://www.forbes.com/sites/johnkoetsier/2018/08/09/reddit-cto-on-fake-news-qanon-harassment-and-running-the-front-page-of-the-internet/#28e2b998210d</a></p>
<p class="list_Paragraph">1. CNN News Stream 2018. “Reddit co-founder: Policing fake news will never be done” <a href="https://edition.cnn.com/videos/business/2018/11/13/alexis-ohanian-reddit-tech.cnn-business/video/playlists/business-big-names-in-tech/">https://edition.cnn.com/videos/business/2018/11/13/alexis-ohanian-reddit-tech.cnn-business/video/playlists/business-big-names-in-tech/</a></p>
<p />
<p><b>News aggregators </b></p>
<p class="list_Paragraph">1. <a href="https://www.wired.com/story/flipboard-news-aggregator-tech-section-update-human-curation/">https://www.wired.com/story/flipboard-news-aggregator-tech-section-update-human-curation/</a></p>
<p class="list_Paragraph">1. <a href="https://www.globenewswire.com/news-release/2018/07/18/1538996/0/en/How-an-Angolan-news-aggregator-is-tackling-the-social-issue-of-fake-news.html">https://www.globenewswire.com/news-release/2018/07/18/1538996/0/en/How-an-Angolan-news-aggregator-is-tackling-the-social-issue-of-fake-news.html</a></p>
<p class="list_Paragraph">1. <a href="https://hackernoon.com/deepsee-io-the-solution-to-fake-news-the-ai-social-aggregation-platform-the-internet-needs-273cb95f10c5">https://hackernoon.com/deepsee-io-the-solution-to-fake-news-the-ai-social-aggregation-platform-the-internet-needs-273cb95f10c5</a></p>
<p class="list_Paragraph">1. <a href="https://medium.com/@timoreilly/the-huffington-post-has-a-fake-news-problem-f68d8e262cec">https://medium.com/@timoreilly/the-huffington-post-has-a-fake-news-problem-f68d8e262cec</a></p>
<p />
<p />
<p />
<p><b>Meta-data</b></p>
<p class="list_Paragraph">a) <b>Overall learning outcomes/competencies</b>: Moral decision-making skills, Moral judgement skills, Moral sensibility, Moral analysis skills, Moral creativity
</p>
<p class="list_Paragraph">b) <b>Theoretical frameworks used to analyse this case:</b> Value ethics, value sensitive design, responsible research and innovation, mediation theory</p>
<p class="list_Paragraph" />
<p class="list_Paragraph">c) <b>Ethical concepts: </b>Value trade-offs, autonomy, openness, transparency, mediation of perception.
</p>
<p class="list_Paragraph">d) <b>Keywords</b>: Fact checking, social media, fake news, community guidelines, algorithm</p>
<p class="list_Paragraph" />
<p class="list_Paragraph">e) <b>Level of education</b>: bachelor, master</p>
<p class="list_Paragraph" />
<p class="list_Paragraph">f) <b>Technology domain</b>: Digital technologies: Social Media
</p>
<p class="list_Paragraph">g) <b>Engineering studies</b>: All engineering students </p>
<p class="list_Paragraph" />
<p class="list_Paragraph">h) <b>Type of education delivery</b>: synchronous, in real life. </p>
<p class="list_Paragraph" />
<p class="list_Paragraph">i) <b>Resources required</b>: standard (books, texts, flipcharts, post-its, etc)</p>
<p class="list_Paragraph" />
<p class="list_Paragraph">j) <b>Length and ECTS</b>: 50 hours, 2 ECTS.</p>
<p class="list_Paragraph" />
<p>4</p>
<p class="footer" />
</body></html>