<!DOCTYPE html>
<html lang="nl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Automatisch nakijken - Discussie en conclusies</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
<header>
    <h1>Discussie en conclusies</h1>
</header>
<main>
    <p>Een mogelijke richting is om een LLM te laten reflecteren op het gegeven antwoord model en
    verbeteringen voor te stellen. Dit zou eventueel wel een duurder "reasoning" model kunnen zijn,
    waarbij een mens de suggesties naloopt en goedkeurt. Het voordeel van deze methode is dat inladen
    van een antwoordmodel wel nog grotendeels automatisch kan gaan en dat het docenten niet veel
    werk hoeft te kosten. Bovendien is er de mogelijkheid om de vragen zelf specifieker te maken,
    wanneer deze nog niet is voorgelegd aan studenten, en dat kan de kwaliteit van nakijken ten goede
    komen. Een mogelijk nadeel van deze methode is dat docenten met weinig prompt ervaring, toch
    nog fouten kunnen maken, die pas tijdens het nakijken zelf zullen blijken.</p>

    <p>Een andere richting is om docenten te laten reageren op opmerkingen waar de LLM mee komt. De
    opmerkingen kunnen dan gebruikt worden om het antwoordmodel te verbeteren. Vervolgens kunnen
    alle antwoorden opnieuw door de LLM gehaald worden, met gebruik van het verbeterde antwoord
    model. Dit proces kan zich herhalen totdat er geen opmerkingen meer zijn. Deze iteratieve methode
    heeft als voordeel, dat de docent continue betrokken is en goed zicht heeft op de gevolgen van
    aanpassingen aan het antwoordmodel. Een nadeel is dat deze methode relatief duur is. Kosten
    kunnen beperkt worden door opmerkingen eerst te laten clusteren. Dit clusteren is vrij goedkoop en
    kan er toe leiden, dat docenten met relatief weinig opmerkingen doornemen, toch veel
    verbeteringen in één keer kunnen aanbrengen. Hoe minder iteraties er nodig zijn om het
    antwoordmodel te verbeteren hoe goedkoper dit proces wordt.</p>

    <h2>Conclusies</h2>

    <p>Het gebruik van LLM als tool bij het nakijken van tentamens lijkt kansrijk. Met relatief weinig
    aanpassingen aan het tentamen kan zo een tool ongeveer 1/3 van het werk uit handen nemen, zonder
    veel op de kwaliteit in te boeten. Vervolg experimenten zouden zich kunnen richten op hoe een
    LLM gebruikt kan worden om het antwoordmodel aan te scherpen voor gebruik bij automatisch
    nakijken. Dit proces van aanscherpen kan vooraf of achteraf het tentamen plaatsvinden, maar vraagt
    in alle gevallen een zekere betrokkenheid van docenten. Daarnaast kan het huidige experiment nog
    uitgebreid worden met meer verschillende LLM aanbieders. Met name Antropic en Google hebben
    interessante modellen op de markt, die het proberen waard zijn in de toekomst.</p>

    <nav class="page-navigation">
        <div class="prev-page">
            <a href="page4.html">Vorige: Meer resultaten</a>
        </div>
    </nav>
</main>
<footer>
    <p>Pagina 5 van 5</p>
</footer>
</body>
</html>