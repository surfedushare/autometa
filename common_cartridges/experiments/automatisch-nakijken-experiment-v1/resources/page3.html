<!DOCTYPE html>
<html lang="nl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Automatisch nakijken - Resultaten</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
<header>
    <h1>Automatisch nakijken</h1>
    <h2>Resultaten</h2>
</header>
<main>
    <p>In totaal zijn er drie LLM's met wisselende configuraties getest. De besteede tijd aan het experiment
    is voornamelijk gaan zitten in evaluatie en verbetering van resultaten. Hierdoor ben ik niet
    toegekomen aan verschillende aanbieders proberen. Alle modellen zijn hierdoor van OpenAI. Per
    model geef ik aan hoe goed het model de taak heeft uitgevoerd, hoeveel werk het bespaart zou
    hebben en wat de kosten zijn om de taak uit te voeren.</p>

    <h3>O1 reasoning</h3>
    <p>Ten tijde van het experiment was dit het beste "reasoning" model<sup>6</sup>. De resultaten zijn teleurstellend.
    Vanwege de lange interne monoloog, die een model uitvoert als onderdeel van de "reasoning" ligt
    het gebruik van tokens hoog. Er wordt afgerekent per token en slechts na ongeveer 40 studenten
    werd mijn ingestelde limiet van €100 bereikt. Geschatte kosten liggen daarmee op €625 euro per
    tentamen.</p>

    <p>De MAE ligt tussen de 0.4 en 1.4 met een gemiddelde van 0.8. De bias is 0.9%, dus die is te
    verwaarlozen. Er waren helaas onvoldoende observaties om significante ICC2 waardes te
    berekenen. Ik ben snel doorgegaan naar goedkopere alternatieven.</p>

    <h3>O1-mini (3n voted)</h3>
    <p>Met O1-mini blijven we bij het "reasoning" paradigma, maar werken we met een model dat
    beperktere capaciteiten heeft. Het wordt voornamelijk gebruikt om mee te programmeren en is heel
    goedkoop. Het is naar mijn weten nog onduidelijk wat precies de effecten zijn van de mengeling
    tussen natuurlijke taal en programmeertaal syntax en semantiek. In het kader van dit experiment
    zijn wel positieve effecten te verwachten, omdat het antwoord uiteindelijk uitgelezen moet worden
    door software en daarbij helpt een voorkeur voor rigoreuze software syntax. Met "3n voted" wordt
    bedoeld dat de vraag 3x is gesteld en het meest gegeven antwoord wordt gekozen als uiteindelijke
    uitkomst.</p>

    <p>Dit model is in staat om ongeveer 39% van de studenten te beoordelen zonder tussenkomst van een
    docent. De kwaliteit van deze oordelen is een stuk beter dan bij O1. De MAE ligt tussen de 0.2 en
    0.9 met een gemiddelde van 0.5. De bias loopt hier iets op naar 4,9%, maar blijft in een redelijke
    marge. Er is helaas slechte correlatie tussen de scores van de LLM en de docenten, die is
    onvoldoende bij alle vragen. Het grote voordeel van dit model zijn de kosten. Zelfs met 3n zijn de
    geschatte kosten voor het tentamen €6,50.</p>

    <div class="footnote">
        <p><sup>6</sup> https://platform.openai.com/docs/guides/reasoning?api-mode=chat</p>
    </div>

    <nav class="page-navigation">
        <div class="prev-page">
            <a href="page2.html">Vorige: Opzet van het experiment</a>
        </div>
        <div class="next-page">
            <a href="page4.html">Volgende: Meer resultaten en conclusie</a>
        </div>
    </nav>
</main>
<footer>
    <p>Pagina 3 van 4</p>
</footer>
</body>
</html>